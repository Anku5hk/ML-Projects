{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Training-FasterRCNN-resnet152.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "j1RpJ7QSe7Iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re, os, random\n",
        "import torch\n",
        "import cv2\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models.detection.faster_rcnn import FasterRCNN\n",
        "import albumentations as A\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
        "\n",
        "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from albumentations import HorizontalFlip, VerticalFlip, RandomCrop\n",
        "\n",
        "device = torch.device('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8YnQkxaFe7I4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HOME_DIR = '../input/global-wheat-detection'\n",
        "SAVE_DIR = '/kaggle/working'\n",
        "os.listdir(HOME_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "qooMAxd2e7JG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read the csv\n",
        "\n",
        "TRAIN_DIR = f'{HOME_DIR}/train/'\n",
        "TEST_DIR = f'{HOME_DIR}/test/'\n",
        "\n",
        "df = pd.read_csv('../input/boxes-repaired/train_clean.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "D88KRM0qe7JQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Train',len(os.listdir(TRAIN_DIR)))\n",
        "print('Test',len(os.listdir(TEST_DIR)))\n",
        "print('unique image id in df',len(df['image_id'].unique()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kJjCaJ7Ie7JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make csv\n",
        "\n",
        "def expand_bbox(x):\n",
        "    r = np.array(re.findall(\"([0-9]+[.]?[0-9]*)\", x))\n",
        "    if len(r) == 0:\n",
        "        r = [-1, -1, -1, -1]\n",
        "    return r\n",
        "\n",
        "df['x1'] = -1\n",
        "df['y1'] = -1\n",
        "df['x2'] = -1\n",
        "df['y2'] = -1\n",
        "df['area'] = -1\n",
        "\n",
        "df[['x1','y1','x2','y2']] = np.stack(df['bbox'].apply(lambda x: expand_bbox(x)))\n",
        "# df.drop(columns=['bbox'], inplace=True)\n",
        "df.drop(columns=['x'], inplace=True)\n",
        "df.drop(columns=['y'], inplace=True)\n",
        "df.drop(columns=['w'], inplace=True)\n",
        "df.drop(columns=['h'], inplace=True)\n",
        "\n",
        "df = df.astype({'x1': 'float32', 'x2': 'float32', \n",
        "                'y1': 'float32', 'y2': 'float32'})\n",
        "\n",
        "df['x2'] = df['x1'].values + df['x2'].values\n",
        "df['y2'] = df['y1'].values + df['y2'].values\n",
        "\n",
        "df['area'] = (df['y2'] - df['y1']) * (df['x2'] - df['x1'])\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8GvY1Spee7Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5 folds\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "df_folds = df[['image_id']].copy()\n",
        "df_folds.loc[:, 'bbox_count'] = 1\n",
        "df_folds = df_folds.groupby('image_id').count()\n",
        "df_folds.loc[:, 'source'] = df[['image_id', 'source']].groupby('image_id').min()['source']\n",
        "df_folds.loc[:, 'stratify_group'] = np.char.add(\n",
        "    df_folds['source'].values.astype(str),\n",
        "    df_folds['bbox_count'].apply(lambda x: f'_{x // 15}').values.astype(str)\n",
        ")\n",
        "df_folds.loc[:, 'fold'] = 0\n",
        "\n",
        "for fold_number, (train_index, val_index) in enumerate(skf.split(X=df_folds.index, y=df_folds['stratify_group'])):\n",
        "    df_folds.loc[df_folds.iloc[val_index].index, 'fold'] = fold_number"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EQrzF_W9e7Js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_folds.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ODkPd2_Re7Jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WheatDataset(Dataset):\n",
        "       \n",
        "    def __init__(self, dataframe, image_ids, data_dir, transforms=None):\n",
        "        super().__init__()\n",
        "        self.df = dataframe \n",
        "        self.image_list = image_ids\n",
        "        self.image_dir = data_dir\n",
        "        self.transforms = transforms\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        image_id = self.image_list[idx]\n",
        "        image_data = self.df.loc[self.df['image_id'] == image_id]\n",
        "        boxes = torch.as_tensor(np.array(image_data[['x1','y1','x2','y2']]), \n",
        "                                dtype=torch.float32)\n",
        "        area = torch.tensor(np.array(image_data['area']), dtype=torch.int64) \n",
        "        labels = torch.ones((image_data.shape[0],), dtype=torch.int64)\n",
        "        iscrowd = torch.zeros((image_data.shape[0],), dtype=torch.uint8)\n",
        "         \n",
        "        target = {}\n",
        "        target['area'] = area\n",
        "        target['labels'] = labels\n",
        "        target['iscrowd'] = iscrowd\n",
        "        \n",
        "        image = cv2.imread((self.image_dir + '/' + image_id + '.jpg'), cv2.IMREAD_COLOR)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        image /= 255.0\n",
        "        \n",
        "        if self.transforms:\n",
        "            \n",
        "            image_transforms = {\n",
        "                                'image': image,\n",
        "                                'bboxes': boxes,\n",
        "                                'labels': labels\n",
        "                                 }\n",
        "            \n",
        "            image_transforms = self.transforms(**image_transforms)\n",
        "            image = image_transforms['image']\n",
        "            \n",
        "            target['boxes'] = torch.as_tensor(image_transforms['bboxes'], dtype=torch.float32)\n",
        "            target['boxes'] = target['boxes'].reshape(-1, 4) # recheck boxes dimension due to error\n",
        "                 \n",
        "        return image, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QJeuBTfne7J5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_transforms():\n",
        "    return A.Compose([\n",
        "          A.RandomSizedCrop(min_max_height=(800, 800), height=1024, width=1024, p=0.5),\n",
        "           A.OneOf([\n",
        "                A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, \n",
        "                                     val_shift_limit=0.2, p=0.9),\n",
        "                A.RandomBrightnessContrast(brightness_limit=0.2, \n",
        "                                           contrast_limit=0.2, p=0.9),\n",
        "              A.RandomGamma(p=0.5),\n",
        "              A.GaussNoise(p=0.5,var_limit=(0, 0.2)),\n",
        "              A.GaussianBlur(p=0.6),\n",
        "              A.IAASharpen(p=0.5),\n",
        "              A.RandomShadow(p=0.3)\n",
        "            ],p=0.9),\n",
        "        \n",
        "        A.ToGray(p=0.2),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.3),\n",
        "        A.RandomBrightnessContrast(p=0.3),\n",
        "        A.Resize(height=1024, width=1024, p=1),\n",
        "        ToTensorV2(p=1.0)\n",
        "        \n",
        "    ], bbox_params=A.BboxParams(\n",
        "            format='pascal_voc',\n",
        "            min_area=0, \n",
        "            min_visibility=0,\n",
        "            label_fields=['labels']\n",
        "        ))\n",
        "\n",
        "def get_valid_transforms():\n",
        "    return A.Compose([\n",
        "        A.Resize(height=1024, width=1024, p=1),\n",
        "        ToTensorV2(p=1.0)\n",
        "    ])\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "45AuUU2ve7KB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# new loader\n",
        "\n",
        "NUM_WORKERS = 16\n",
        "BATCH_SIZE = 8\n",
        "fold_number = 0\n",
        "\n",
        "train_dataset = WheatDataset(\n",
        "    image_ids=df_folds[df_folds['fold'] != fold_number].index.values,\n",
        "    data_dir=TRAIN_DIR,\n",
        "    dataframe=df,\n",
        "    transforms=get_train_transforms()\n",
        ")\n",
        "train_dataloader = DataLoader(train_dataset, \n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              sampler=RandomSampler(train_dataset),\n",
        "                              num_workers=NUM_WORKERS,\n",
        "                              collate_fn=collate_fn)\n",
        "\n",
        "validation_dataset = WheatDataset(\n",
        "    image_ids=df_folds[df_folds['fold'] == fold_number].index.values,\n",
        "    data_dir=TRAIN_DIR,\n",
        "    dataframe=df,\n",
        "    transforms=get_valid_transforms()\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(validation_dataset, \n",
        "                              batch_size=4,\n",
        "                              sampler=SequentialSampler(validation_dataset),\n",
        "                              shuffle=False, \n",
        "                              num_workers=NUM_WORKERS,\n",
        "                              collate_fn=collate_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PxeHN7AGe7KJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_sample(sample):\n",
        "    image, target = sample\n",
        "    boxes = target['boxes'].cpu().numpy().astype(np.int32)\n",
        "\n",
        "    numpy_image = image.permute(1,2,0).cpu().numpy()\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
        "\n",
        "    for box in boxes:\n",
        "        cv2.rectangle(numpy_image, (box[0], box[1]), (box[2],  box[3]), (0, 1, 0), 2)\n",
        "\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(numpy_image);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SqMKBtvKe7KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_sample(train_dataset[30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "T7bhuPOWe7KY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_dataset), len(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3TIB28cse7Kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JKpaPyQje7Km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "backbone = resnet_fpn_backbone('resnet152', pretrained=True)\n",
        "model = FasterRCNN(backbone, num_classes=2).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Cypw0Qm2e7Kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot lr\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "optimizer = torch.optim.AdamW(params, lr=0.001, weight_decay=0.001)\n",
        "# optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
        "# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=6, eta_min=0, last_epoch=-1) # T_max is max iteration\n",
        "\n",
        "EPOCHS = 25\n",
        "lrs = []\n",
        "for i in range(EPOCHS):\n",
        "    # lr = er.get_last_lr()[0]\n",
        "    lr1 = optimizer.param_groups[0][\"lr\"]\n",
        "    lrs.append(lr1)\n",
        "    # print(f'Step: {i},LR: {lr}')\n",
        "    lr_scheduler.step()\n",
        "plt.plot([i for i in range(EPOCHS)], lrs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LiDhMAmWe7Kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\n",
        "       by https://github.com/Bjarten/early-stopping-pytorch\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "        \n",
        "    def __call__(self, val_loss):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sKjJjRTwe7K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# metric\n",
        "\n",
        "class Averager:\n",
        "    def __init__(self):\n",
        "        self.current_total = 0.0\n",
        "        self.iterations = 0.0\n",
        "\n",
        "    def send(self, value):\n",
        "        self.current_total += value\n",
        "        self.iterations += 1\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        if self.iterations == 0:\n",
        "            return 0\n",
        "        else:\n",
        "            return 1.0 * self.current_total / self.iterations\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_total = 0.0\n",
        "        self.iterations = 0.0\n",
        "    \n",
        "def save_model(path, best_loss):\n",
        "    model.eval()\n",
        "    torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': lr_scheduler.state_dict(),\n",
        "            'best_summary_loss': best_loss,\n",
        "            'epoch': epoch+1,\n",
        "        }, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "o1YMOv1oe7K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "model.train()\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "early_stopping = EarlyStopping(patience=5, verbose=True)\n",
        "\n",
        "optimizer = torch.optim.AdamW(params, lr=0.001, weight_decay=0.0001)\n",
        "# optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
        "# lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=6, eta_min=0, last_epoch=-1)\n",
        "#lr_scheduler = None\n",
        "\n",
        "num_epochs = 10\n",
        "Train_losses = []\n",
        "Valid_losses = []\n",
        "loss_hist = Averager()\n",
        "best_loss = 1.5\n",
        "prev_epochs = 0\n",
        "# grad_acc_steps = 16\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    loss_hist.reset()\n",
        "\n",
        "    for step, (images, targets) in enumerate(train_dataloader):\n",
        "        \n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        loss_value = losses.item()\n",
        "\n",
        "        loss_hist.send(loss_value)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    Train_losses.append(loss_hist.value)\n",
        "    print(f\"Epoch #{epoch+1} train_loss: {loss_hist.value}\")\n",
        "    loss_hist.reset()\n",
        "\n",
        "    for images, targets in valid_dataloader:\n",
        "        \n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "\n",
        "        val_losses = sum(loss for loss in loss_dict.values())\n",
        "        val_loss = val_losses.item()\n",
        "\n",
        "        loss_hist.send(val_loss)\n",
        "\n",
        "    Valid_losses.append(loss_hist.value)\n",
        "    print(f\"valid_loss: {loss_hist.value}\")\n",
        "\n",
        "    # update the learning rate\n",
        "    if lr_scheduler is not None:\n",
        "        lr_scheduler.step()\n",
        "\n",
        "     # early stoping\n",
        "    early_stopping(Valid_losses[-1])\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break    \n",
        "        \n",
        "    if best_loss > Valid_losses[-1]:\n",
        "\n",
        "        best_loss = Valid_losses[-1]\n",
        "        save_model(f'{SAVE_DIR}/best-checkpoint-{str(epoch).zfill(3)}epoch.bin', best_loss)\n",
        "        # remove previous more than 3 saves\n",
        "        for path in sorted(glob(f'{SAVE_DIR}/best-checkpoint-*epoch.bin'))[:-3]:\n",
        "             os.remove(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "73LzTc4me7LE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# last save \n",
        "\n",
        "save_model(f'{SAVE_DIR}/last-checkpoint-{str(num_epochs+prev_epochs).zfill(3)}epoch.bin', Valid_losses[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wWaTv1XQe7LO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}